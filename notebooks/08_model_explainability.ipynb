{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8089579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "844843af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split: (32502, 8) (32502,)\n",
      "Validation split: (10834, 8) (10834,)\n",
      "Test split: (10834, 8) (10834,)\n"
     ]
    }
   ],
   "source": [
    "processed_data_dir = Path(\"data/processed\")\n",
    "interim_data_dir = Path(\"data/interim\")\n",
    "\n",
    "X_train = pd.read_csv(processed_data_dir / \"X_train_enhanced.csv\")\n",
    "X_val   = pd.read_csv(processed_data_dir / \"X_val_enhanced.csv\")\n",
    "X_test  = pd.read_csv(processed_data_dir / \"X_test_enhanced.csv\")\n",
    "\n",
    "y_train = pd.read_csv(processed_data_dir / \"y_train_enhanced.csv\").squeeze(\"columns\")\n",
    "y_val   = pd.read_csv(processed_data_dir / \"y_val_enhanced.csv\").squeeze(\"columns\")\n",
    "y_test  = pd.read_csv(processed_data_dir / \"y_test_enhanced.csv\").squeeze(\"columns\")\n",
    "\n",
    "print(\"Train split:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation split:\", X_val.shape, y_val.shape)\n",
    "print(\"Test split:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4818692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "model = joblib.load(\"outputs/models/xgb_model.pkl\")\n",
    "print(\"✅ Model loaded successfully.\")\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6430b3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shap_explanation(model, X_sample, feature_names, class_names):\n",
    "    explainer = shap.Explainer(model)\n",
    "    shap_values = explainer(X_sample)\n",
    "\n",
    "    # Get model prediction for the sample\n",
    "    pred_class = model.predict(X_sample)[0]\n",
    "\n",
    "    # shap_values.values has shape (n_samples, n_classes, n_features)\n",
    "    class_index = pred_class\n",
    "    sample_values = shap_values.values[0, class_index]\n",
    "\n",
    "    # Display feature contributions\n",
    "    print(f\"=== SHAP Explanation for Predicted Class: {class_names[pred_class]} ===\")\n",
    "    print(\"Top feature contributions:\")\n",
    "\n",
    "    # Sort features by absolute SHAP value (importance)\n",
    "    sorted_idx = np.argsort(np.abs(sample_values))[::-1]\n",
    "\n",
    "    for i in sorted_idx[:10]:  # top 10\n",
    "        feature = feature_names[i]\n",
    "        value = sample_values[i]\n",
    "        direction = \"increases\" if value > 0 else \"decreases\"\n",
    "        print(f\"{feature:<20}: {direction} probability by {abs(value):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "206211fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SHAP Explanation for Predicted Class: Medium ===\n",
      "Top feature contributions:\n",
      "hour_cos            : increases probability by 1.152\n",
      "hour_sin            : decreases probability by 0.803\n",
      "dow_sin             : decreases probability by 0.218\n"
     ]
    }
   ],
   "source": [
    "get_shap_explanation(model, X_test.iloc[[1000]], X_test.columns.to_list(), [\"Low\",\"Medium\",\"High\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "128dd6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SHAP Explanation for Predicted Class: Low ===\n",
      "Top feature contributions:\n",
      "hour_cos            : increases probability by 0.206\n",
      "dow_sin             : decreases probability by 0.128\n",
      "hour_sin            : decreases probability by 0.066\n"
     ]
    }
   ],
   "source": [
    "get_shap_explanation(model, X_test.iloc[[3000]], X_test.columns.to_list(), [\"Low\",\"Medium\",\"High\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7d40d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SHAP Explanation for Predicted Class: High ===\n",
      "Top feature contributions:\n",
      "hour_cos            : decreases probability by 0.371\n",
      "hour_sin            : increases probability by 0.306\n",
      "dow_sin             : increases probability by 0.006\n"
     ]
    }
   ],
   "source": [
    "get_shap_explanation(model, X_test.iloc[[4000]], X_test.columns.to_list(), [\"Low\",\"Medium\",\"High\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "001da4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_with_lime(model, X_train, X_test, feature_names, sample_index=0):\n",
    "    # Convert to NumPy arrays\n",
    "    X_train_np = X_train.values if hasattr(X_train, \"values\") else X_train\n",
    "    X_test_np = X_test.values if hasattr(X_test, \"values\") else X_test\n",
    "\n",
    "    # Create LIME explainer\n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "        X_train_np,\n",
    "        feature_names=feature_names,\n",
    "        mode='classification'\n",
    "    )\n",
    "\n",
    "    # Explain one prediction\n",
    "    explanation = explainer.explain_instance(\n",
    "        X_test_np[sample_index],\n",
    "        model.predict_proba,\n",
    "        num_features=5\n",
    "    )\n",
    "\n",
    "    # Display results\n",
    "    print(f\"LIME explanation for sample {sample_index}:\")\n",
    "    for feature, contribution in explanation.as_list():\n",
    "        direction = \"increases\" if contribution > 0 else \"decreases\"\n",
    "        print(f\"- {feature} {direction} prediction by {abs(contribution):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "255daae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIME explanation for sample 1000:\n",
      "- hour_sin > 0.71 increases prediction by 0.245\n",
      "- is_holiday <= 0.00 decreases prediction by 0.214\n",
      "- -0.00 < hour_cos <= 0.71 increases prediction by 0.166\n",
      "- month_cos <= -0.50 increases prediction by 0.136\n",
      "- 0.00 < dow_sin <= 0.78 decreases prediction by 0.104\n"
     ]
    }
   ],
   "source": [
    "explain_with_lime(model, X_train, X_test, X_test.columns.to_list(), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c39b535f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIME explanation for sample 3000:\n",
      "- 0.00 < hour_sin <= 0.71 increases prediction by 0.201\n",
      "- is_holiday <= 0.00 decreases prediction by 0.193\n",
      "- dow_sin <= -0.78 increases prediction by 0.179\n",
      "- hour_cos <= -0.71 decreases prediction by 0.169\n",
      "- 0.00 < month_cos <= 0.87 decreases prediction by 0.100\n"
     ]
    }
   ],
   "source": [
    "explain_with_lime(model, X_train, X_test, X_test.columns.to_list(), 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "282aca7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIME explanation for sample 4000:\n",
      "- hour_sin <= -0.71 decreases prediction by 0.293\n",
      "- is_holiday <= 0.00 decreases prediction by 0.180\n",
      "- -0.71 < hour_cos <= -0.00 decreases prediction by 0.150\n",
      "- month_cos <= -0.50 increases prediction by 0.123\n",
      "- -0.50 < month_sin <= 0.00 decreases prediction by 0.076\n"
     ]
    }
   ],
   "source": [
    "explain_with_lime(model, X_train, X_test, X_test.columns.to_list(), 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b46f45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_importance(model, X_test, y_test, feature_names):\n",
    "    # Get baseline accuracy\n",
    "    baseline_score = model.score(X_test, y_test)\n",
    "    importance_scores = {}\n",
    "    # Convert to NumPy arrays\n",
    "    X_test_np = X_test.values if hasattr(X_test, \"values\") else X_test\n",
    "    # Test each feature\n",
    "    for i, feature in enumerate(feature_names):\n",
    "        # Make a copy and shuffle this feature\n",
    "        X_shuffled = X_test_np.copy()\n",
    "        X_shuffled[:, i] = np.random.permutation(X_shuffled[:, i])\n",
    "        \n",
    "        # See how much performance drops\n",
    "        shuffled_score = model.score(X_shuffled, y_test)\n",
    "        importance = baseline_score - shuffled_score\n",
    "        importance_scores[feature] = importance\n",
    "        \n",
    "        print(f\"{feature}: {importance:.3f} importance\")\n",
    "    \n",
    "    return importance_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d64706b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hour_sin: 0.179 importance\n",
      "hour_cos: 0.181 importance\n",
      "dow_sin: 0.120 importance\n",
      "dow_cos: 0.005 importance\n",
      "month_sin: 0.060 importance\n",
      "month_cos: 0.133 importance\n",
      "is_holiday: 0.011 importance\n",
      "is_holiday_window: 0.008 importance\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hour_sin': 0.17906590363669928,\n",
       " 'hour_cos': 0.18091194388037657,\n",
       " 'dow_sin': 0.11990031382684141,\n",
       " 'dow_cos': 0.004799704633560942,\n",
       " 'month_sin': 0.05962709987077708,\n",
       " 'month_cos': 0.1333764076056857,\n",
       " 'is_holiday': 0.010983939449879965,\n",
       " 'is_holiday_window': 0.008122577072180115}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_importance(model, X_test, y_test, X_test.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c155d215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_importance_methods(model, X, y, feature_names):\n",
    "    results = {}\n",
    "    \n",
    "    # Built-in importance (if available)\n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        results['Built-in'] = dict(zip(feature_names, model.feature_importances_))\n",
    "    \n",
    "    # Permutation importance (simplified)\n",
    "    baseline = model.score(X, y)\n",
    "    # Convert to NumPy arrays\n",
    "    X_np = X.values if hasattr(X, \"values\") else X\n",
    "    perm_importance = {}\n",
    "    for i, feature in enumerate(feature_names):\n",
    "        X_copy = X_np.copy()\n",
    "        X_copy[:, i] = np.random.permutation(X_copy[:, i])\n",
    "        score_drop = baseline - model.score(X_copy, y)\n",
    "        perm_importance[feature] = max(0, score_drop)\n",
    "    \n",
    "    results['Permutation'] = perm_importance\n",
    "    \n",
    "    # Compare top features\n",
    "    print(\"Top 5 features by each method:\")\n",
    "    for method, scores in results.items():\n",
    "        top_features = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        print(f\"\\n{method}:\")\n",
    "        for feature, score in top_features:\n",
    "            print(f\"  {feature}: {score:.3f}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c85b15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 features by each method:\n",
      "\n",
      "Built-in:\n",
      "  hour_cos: 0.222\n",
      "  dow_sin: 0.185\n",
      "  hour_sin: 0.180\n",
      "  month_cos: 0.143\n",
      "  month_sin: 0.090\n",
      "\n",
      "Permutation:\n",
      "  hour_cos: 0.178\n",
      "  hour_sin: 0.169\n",
      "  month_cos: 0.127\n",
      "  dow_sin: 0.111\n",
      "  month_sin: 0.063\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Built-in': {'hour_sin': np.float32(0.17983447),\n",
       "  'hour_cos': np.float32(0.22179714),\n",
       "  'dow_sin': np.float32(0.18508533),\n",
       "  'dow_cos': np.float32(0.040876053),\n",
       "  'month_sin': np.float32(0.09048686),\n",
       "  'month_cos': np.float32(0.14262348),\n",
       "  'is_holiday': np.float32(0.08443204),\n",
       "  'is_holiday_window': np.float32(0.05486457)},\n",
       " 'Permutation': {'hour_sin': 0.16854347424773852,\n",
       "  'hour_cos': 0.1775890714417574,\n",
       "  'dow_sin': 0.11140852870592577,\n",
       "  'dow_cos': 0.004061288536090002,\n",
       "  'month_sin': 0.06294997230939625,\n",
       "  'month_cos': 0.12691526675281517,\n",
       "  'is_holiday': 0.011537751522983197,\n",
       "  'is_holiday_window': 0.008768691157467146}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_importance_methods(model, X_test, y_test, X_test.columns.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56261c19",
   "metadata": {},
   "source": [
    "# Model Explainability Summary\n",
    "\n",
    "## Objective\n",
    "The goal of this stage was to **interpret model behavior** and understand **why specific predictions were made**—both at a local (single instance) and global (dataset-wide) level.  \n",
    "We applied **SHAP** and **LIME** explainability frameworks to our tuned classification model (XGBoost with holiday features).\n",
    "\n",
    "---\n",
    "\n",
    "## Global Model Insights\n",
    "\n",
    "### Feature Importance (SHAP Summary)\n",
    "- **hour_cos**, **hour_sin**, and **dow_sin** remain dominant predictors, confirming the strong influence of **daily and weekly demand cycles**.  \n",
    "- **is_holiday** and **is_holiday_window** now appear among the top five features, validating that **public holidays significantly affect demand behavior**.  \n",
    "- **month_cos** captures broader seasonal trends but contributes less than daily and holiday effects.  \n",
    "- The weakest feature continues to be **dow_cos**, suggesting redundancy with `dow_sin`.\n",
    "\n",
    "**Interpretation:**  \n",
    "Electricity demand patterns are driven primarily by **time-of-day and day-of-week signals**, with **holidays introducing meaningful corrections** that help the model better classify Medium demand periods.\n",
    "\n",
    "---\n",
    "\n",
    "## Local Explanations (SHAP & LIME)\n",
    "\n",
    "### Example 1 – Medium Demand Prediction\n",
    "- **Positive contributors:** `hour_cos` and `is_holiday` pushed the prediction toward Medium demand, reflecting reduced industrial load on public holidays.  \n",
    "- **Negative contributors:** `hour_sin` and `month_sin` slightly decreased Medium probability, consistent with non-peak seasonal hours.  \n",
    "- The SHAP waterfall plot confirmed that the prediction was mainly shaped by **holiday timing** and **midday hour positioning**.\n",
    "\n",
    "### Example 2 – High Demand Prediction\n",
    "- Driven upward by `hour_sin` and `dow_sin` (weekday evening patterns).  \n",
    "- Counteracted by `is_holiday`, which lowered High demand probability during non-working days.\n",
    "\n",
    "### LIME Comparison\n",
    "- LIME explanations corroborated SHAP findings, highlighting the same dominant factors (`hour_cos`, `is_holiday`, `dow_sin`) and offering intuitive human-readable rules:\n",
    "  - *“hour_cos > 0.5 increases probability of Medium demand”*  \n",
    "  - *“is_holiday = 1 decreases High demand likelihood.”*\n",
    "\n",
    "---\n",
    "\n",
    "## Global vs Local Alignment\n",
    "- Both global SHAP and local explanations tell a consistent story:  \n",
    "  - **Time-based cyclical features** dominate.  \n",
    "  - **Holiday features** refine Medium-tier accuracy without overfitting.  \n",
    "  - **High demand** remains harder to capture—mainly distinguished by weekday evening peaks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad68f64",
   "metadata": {},
   "source": [
    "# Model Decision Communication – \"Medium Demand on a Public Holiday\"\n",
    "\n",
    "**Scenario:**  \n",
    "The model predicts **Medium electricity demand** for a specific public holiday, based on time, day, and historical consumption patterns.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Executive Summary (for Decision-Maker / Manager)\n",
    "**Tone:** Strategic, outcome-focused, concise, data-backed.\n",
    "\n",
    "**Explanation:**  \n",
    "The forecasting model predicts **medium energy demand** for tomorrow’s public holiday.  \n",
    "This aligns with historical patterns where industrial consumption drops while residential use rises, creating a balanced load overall.  \n",
    "Confidence in this forecast is high (≈85%), supported by key factors such as **hour of the day**, **holiday status**, and **weekday context**.  \n",
    "Operational teams can plan for a stable grid load with moderate production reserves, avoiding overgeneration and unnecessary costs.  \n",
    "No critical anomalies detected.\n",
    "\n",
    "**What they need to know:**  \n",
    "- The model is reliable and consistent with past data.  \n",
    "- The decision helps optimize production and cost efficiency.  \n",
    "- Risk level is low; no intervention required.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Customer Service Explanation (for Frontline Representative)\n",
    "**Tone:** Practical, action-oriented, simplified technical detail.\n",
    "\n",
    "**Explanation:**  \n",
    "Our energy forecasting system shows that demand will likely be **moderate** tomorrow because it’s a public holiday.  \n",
    "That means factories and offices will use less power, while homes will use a bit more during the day.  \n",
    "The prediction helps our operations team plan energy generation efficiently so customers won’t experience any supply issues.  \n",
    "If customers ask about their usage, it’s expected to be similar to a typical weekend day.\n",
    "\n",
    "**What they need to know:**  \n",
    "- Why the forecast matters for customers (stable supply, no outages).  \n",
    "- How to explain this simply without mentioning algorithms.  \n",
    "- Confidence level and expected stability.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Customer Explanation (for the Affected Person)\n",
    "**Tone:** Clear, empathetic, relatable, avoids jargon.\n",
    "\n",
    "**Explanation:**  \n",
    "Tomorrow’s energy use is expected to stay at **normal levels** — not too high or too low — because many workplaces will be closed for the holiday, while more people will be home using appliances and heating.  \n",
    "Our system uses patterns from previous holidays to help keep the electricity supply steady and costs fair.  \n",
    "You don’t need to do anything — this just helps us plan ahead so your service runs smoothly.\n",
    "\n",
    "**What they need to know:**  \n",
    "- The outcome affects reliability and fairness, not personal data.  \n",
    "- It’s routine, safe, and designed to benefit them.  \n",
    "- Builds trust in the company’s foresight and care.\n",
    "\n",
    "---\n",
    "\n",
    "## Summary of Communication Strategy\n",
    "\n",
    "| Audience | Focus | Style | Detail Level | Goal |\n",
    "|-----------|--------|--------|---------------|------|\n",
    "| **Executive** | Operational impact, ROI, risk | Analytical, concise | Medium | Ensure confidence in decision-making |\n",
    "| **Customer Service Rep** | Customer-facing clarity | Conversational, practical | Low–Medium | Enable consistent, accurate communication |\n",
    "| **Customer** | Transparency, reassurance | Simple, empathetic | Low | Build trust and comfort |\n",
    "\n",
    "---\n",
    "\n",
    "By tailoring language and depth, the same model decision becomes understandable, relevant, and confidence-building for every audience.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0cc35d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
